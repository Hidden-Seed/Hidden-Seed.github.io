[{"title":"计算机体系结构（一） - 量化分析与设计基础","url":"/posts/2815a773/","content":"第一章  量化分析与设计基础1. 体系结构的复兴摩尔定律：晶体管数量的指数级增长（已终结）\n登纳德缩放比例定律：功率密度的恒定（已终结）\n体系结构\n指令集设计（不包含实现）$\\rightarrow$ 组成+硬件\n\n技术趋势：1. 带宽胜过延迟；2. 连线的困难。\n指令级并行$\\rightarrow$数据级并行$\\rightarrow$线程级并行\n2. 量化分析方法2.1 功耗（Power）与能耗（Energy）\n\\text{Energy}_\\text{dynamic} \\propto 1/2 \\times \\text{Capacitive load} \\times \\text{Voltage}^{2}\n\\text{Power}_\\text{dynamic} \\propto 1/2 \\times \\text{Capacitive load} \\times \\text{Voltage}^{2} \\times \\text{Frequency switched}\n\\text{Power}_\\text{static} \\propto \\text{Current}_\\text{static} \\times \\text{Voltage}\nDo nothing well\nDynamic voltage-frequency scaling (DVFS)\nDesign for the typical case\nOverclocking\n\n2.2 成本时间、产量、大众化\n集成电路的成本\n\n\\text{wafer} \\xrightarrow{\\text{tested and chopped}} \\text{die}\n\\text{Cost of integrated circuit} = \\frac{\\text{Cost of die} + \\text{Cost of testing die} + \\text{Cost of packaging and final test}}{\\text{Final test yield}}\n\\text{Cost of die} = \\frac{\\text{Cost of wafer}}{\\text{Dies per wafer} \\times \\text{Die yield}}\n\\text{Dies per wafer} = \\frac{\\pi \\times {(\\text{Wafer diameter}/2)}^2}{\\text{Die area}} - \\frac{\\pi \\times \\text{Wafer diameter}}{\\sqrt{\\pi \\times \\text{Die area}}}\n\\text{Die yield} = \\text{Wafer yield} \\times (1 + \\text{Defects per unit area} \\times \\text{Die area})^{N}制造工艺决定了晶圆成本、晶圆良率和  单位面积上的缺陷数，所以设计人员唯一能够控制的就是晶片面积。\n\n2.3 可信任度2.3.1 模块可靠性（Module reliability）平均无故障时间（mean time to failure, MTTF）\n故障率（rate of failure = 1/MTTF）：通常以运行10亿小时发生的 故障数来表示，被称为FIT（failures in time）\n\n1\\, \\text{FIT} = 1\\, \\text{failure per } 10^9 \\text{ hours}\n\\lambda \\text{(failures/hour)} = \\frac{\\text{FIT}}{10^9}\n\\text{FIT} = \\lambda \\times 10^9 = \\frac{10^9}{\\text{MTTF}}平均修复时间（mean time to repair, MTTR）\n平均故障间隔时间（mean time between failures, MTBF）= MTTF + MTTR\n如果一组模块的生存期呈指数分布，也就是说模块的老化对于故障概率的影响不大，那么「这一组模块的整体故障率就是这些模块的  故障率之和」。\n一个模块的寿命 $T$ 服从指数分布：\n\nf(t) = \\lambda e^{-\\lambda t}, \\quad t \\ge 0其中 $\\lambda$ 是故障率（failure rate）。\n指数分布的特点：无记忆性（memoryless）\n\nP(T > t + s \\mid T > s) = P(T > t)假设系统中有 $n$ 个模块，它们相互独立，且寿命都服从指数分布：\n\n\\text{模块 } i: f_i(t) = \\lambda_i e^{-\\lambda_i t}系统在「任一模块失效」时就算系统失效（即串联系统）。\n系统可靠性函数（即“系统存活到 t 的概率”）为：\n\nR_{\\text{sys}}(t) = e^{-(\\lambda_1 + \\lambda_2 + \\cdots + \\lambda_n)t}这仍然是一个指数分布，参数是所有模块 λ 的和。\n系统故障率由上式可得：\n\n\\lambda_{\\text{sys}} = \\lambda_1 + \\lambda_2 + \\cdots + \\lambda_n2.3.2 模块可用性（ Module availability）\n\\text{Module availability} = \\frac{\\text{MTTF}}{\\text{MTTF} + \\text{MTTR}}2.3.3 一个例子磁盘子系统经常备有冗余电源，以提高可信任度。假设一个电源足以运行磁盘子系统，而且我们要添加一个冗余电源。 \n我们需要一个公式来表明当可以容忍一个故障并仍能提供服务时的情景。为了简化计算，假定组件的生存期呈指数分布，而且组件故障之间没有相关性。\n冗余电源对的MTTF就是两个量的比值，分子是从初始时刻到一个电源发生故障的平均时间， 分母是在更换第一个电源之前另一个电源也发生故障的概率。\n\n因此，如果在修复第  一个故障之前发生第二个故障的可能性很小，那么电源对的MTTF就很大。 由于我们有两个电源，而且故障独立，所以在一个电源发生故障之前的平均时间为$\\text{MTTF}_\\text{电源} / 2$。发生第二个故障的概率有一个很好的近似：用MTTR除以另一个电源  发生故障之前的平均时间。因此，冗余电源对的合理近似为：\n\n\\text{MTTF}_{\\text{power supply pair}} = \\dfrac{\\text{MTTF}_{\\text{power supply}}/2}{\\dfrac{\\text{MTTR}_{\\text{power supply}}}{\\text{MTTF}_{\\text{power supply}}}} = \\dfrac{\\text{MTTF}_{\\text{power supply}}^2 / 2}{\\text{MTTR}_{\\text{power supply}}} = \\dfrac{\\text{MTTF}_{\\text{power supply}}^2}{2 \\times \\text{MTTR}_{\\text{power supply}}}$\\text{MTTF}{\\text{power supply}} = 2000 \\text{ h}$，$\\text{MTTR}{\\text{power supply}} = 24 \\text{ h}$，则 $\\text{MTTF}_{\\text{power supply pair}} \\approx 833 333 333 \\text{ h}$，提高约4150倍\n2.4 性能\nn = \\cfrac{\\text{Execution time}_{Y}}{\\text{Execution time}_{X}} = \\dfrac{\\dfrac{1}{\\text{Performance}_{Y}}}{\\dfrac{1}{\\text{Performance}_{X}}} = \\dfrac{\\text{Performance}_{X}}{\\text{Performance}_{Y}} SPEC基准测试：SPEC - Standard Performance Evaluation Corporation\n桌面基准测、服务器基准测试\nSPECRatio：将基准计 算机上的执行时间除以待评估计算机上的执行时间，得到一个与性能成正比的比值。\n对于每个基准程序 $i$，定义：\n\n\\text{SPECRatio}_i = \\frac{\\text{Reference Time}_i}{\\text{Test System Time}_i}\n\\text{SPECint (或 SPECfp)} = \\left( \\prod_{i=1}^{n} \\text{SPECRatio}_i \\right)^{1/n}几何平均值之比等于性能比值的几何平均值，且$\\text{SPECRatio}$基准计算机的选择无关紧要。\n\n\\dfrac{\\text{Geometric mean}_\\text{A}}{\\text{Geometric mean}_\\text{B}} = \\dfrac{\\sqrt[n]{\\displaystyle \\prod_{i=1}^{n} \\text{SPECRatio A}_i}}{\\sqrt[n]{\\displaystyle \\prod_{i=1}^{n} \\text{SPECRatio B}_i}} = \\sqrt[n]{\\prod_{i=1}^{n} \\dfrac{\\text{SPECRatio A}_i}{\\text{SPECRatio B}_i}}\n = \\sqrt[n]{\\prod_{i=1}^{n} \\dfrac{\\dfrac{\\text{Execution time}_{\\text{reference}_i}}{\\text{Execution time}_{\\text{A}_i}}}{\\dfrac{\\text{Execution time}_{\\text{reference}_i}}{\\text{Execution time}_{\\text{B}_i}}}} = \\sqrt[n]{\\prod_{i=1}^{n} \\dfrac{\\text{Execution time}_{\\text{B}_i}}{\\text{Execution time}_{\\text{A}_i}}} = \\sqrt[n]{\\prod_{i=1}^{n} \\dfrac{\\text{Performance}_{\\text{B}_i}}{\\text{Performance}_{\\text{A}_i}}}\n3. 计算机设计的量化原理\n提高并行性\n局部性原理（空间局部+时间局部）\n重点关注常见情形\n\n3.1 Amdahl‘s Law加速比（Speedup）\n\n\\text{Speedup} = \\dfrac{\\text{Performance for entire task using the enhancement when possible}}{\\text{\nPerformance for entire task without using the enhancement}}\n\\text{Speedup} = \\dfrac{\\text{Execution time for entire task without using the enhancement}}{\\text{Execution time for entire task using the enhancement when possible\n}}加速比取决于下面两个因素：\n\n原计算机计算时间中可改进部分所占的比例：改进比例（$\\text{Fraction}_\\text{enhanced}$），小于或等于1。\n通过改进执行模式得到的改进，也就是说在为整个程序使用这一执行模式时，任务的运行速度会提高多少倍：改进加速比（$\\text{Speedup}_\\text{enhanced}$），大于1。\n\n\n\\text{Execution time}_\\text{new} = \\text{Execution time}_\\text{old} \\times \\left ( (1 - \\text{Fraction}_\\text{enhanced}) + \\dfrac{\\text{Fraction}_\\text{enhanced}}{\\text{Speedup}_\\text{enhanced}} \\right )\n\\text{Speedup}_\\text{overall} = \\dfrac{\\text{Execution time}_\\text{old}}{\\text{Execution time}_\\text{new}} = \\dfrac{1}{(1 - \\text{Fraction}_\\text{enhanced}) + \\dfrac{\\text{Fraction}_\\text{enhanced}}{\\text{Speedup}_\\text{enhanced}}}3.2 处理器性能公式程序的CPU时间表示：\n\n\\text{CPU time} = \\text{CPU clock cycles for a program} \\times  \\text{Clock cycle time}\n\\text{CPU time} = \\dfrac{\\text{CPU clock cycles for a program}}{\\text{Clock rate}}指令路径长度或指令数（instruction count, IC）：计算所执行的指令数。\n每条指令的时钟周期数（clock cycles per instruction, CPI）的平均值：\n\n\\text{CPI} = \\dfrac{\\text{CPU clock cycles for a program}}{\\text{Instruction count}}\n \\text{Clock cycles} = \\text{IC} \\times \\text{CPI}\n\\text{CPU time} = \\text{Instruction count} \\times \\text{Cycles per instruction} \\times \\text{Clock cycle time}\n= \\dfrac{\\text{Instructions}}{\\text{Program}} \\times \\dfrac{\\text{Clock cycles}}{\\text{Instruction}} \\times \\dfrac{\\text{Seconds}}{\\text{Clock cycle}} = \\dfrac{\\text{Seconds}}{\\text{Program}}处理器性能取决于3个特性：时钟周期（或时钟频率）、每条指令的时钟 周期数和指令数。\nCPU时间也取决于这3个特性：3个特性中任意一项改进10%,  将使CPU时间改进10%。\n\n时钟周期时间：硬件技术与组成。 \nCPI：组成与指令集体系结构。\n指令数：指令集体系结构和编译器技术。 \n\n\n\n\\text{CPU clock cycles} = \\sum_{i=1}^{n}{\\text{IC}_i \\times \\text{CPI}_i}\n$\\text{IC}_i$：一个程序中第i个指令的执行次数；\n$\\text{CPI}_i$：示第i个指令的每条指令平均时钟周期数。\n\n\n\\text{CPU time} = \\left( \\sum_{i=1}^{n}{\\text{IC}_i \\times \\text{CPI}_i} \\right) \\times \\text{Clock cycle time}\n\\text{CPI}_\\text{overall} = \\dfrac{\\displaystyle \\sum_{i=1}^{n}{\\text{IC}_i \\times \\text{CPI}_i}}{\\text{Instruction count}} = \\sum_{i=1}^{n}{\\dfrac{\\text{IC}_i}{\\text{Instruction count}} \\times \\text{CPI}_i} $\\text{CPI}$ 的后一种计算形式使用了各个 $\\text{CPI}_i$ ，和该指令在一个程序中所占的比例。\nAppendix AA.1 为什么较新的指令集都不在指令中直接访问存储器，而是通过载入-存储的方式？\n✅ 越新的 ISA（如 RISC-V、MIPS、ARM、SPARC）都采用 Load/Store 架构，而老架构（如 x86、VAX、PDP-11）则常允许在任意指令中直接访问内存。\n\nA.1.1 背景：两种架构风格\n\n\n\n架构类型\n特点\n代表\n\n\n\n\nCISC（Complex Instruction Set Computer）\n一条指令可以直接访问内存、执行复杂操作（如 ADD [mem1], [mem2]）\nx86, VAX, 68000\n\n\nRISC（Reduced Instruction Set Computer）\n只允许专门的 Load/Store 指令访问内存，运算只能在寄存器间进行\nMIPS, ARM, RISC-V\n\n\n\n\nA.1.2 为什么现代 ISA 都采用 Load/Store 架构？从 硬件实现、性能优化、并行化 的角度，这是必然选择：\n\n简化流水线设计（Pipeline-friendly）\n在早期 CISC 架构中，一条指令可能要取操作码、计算内存地址、发起访存、取回数据、执行算术、写回结果，这使得一条指令的执行时间无法预测，很难做到指令级并行（ILP）。而 Load/Store 架构中，Load/Store 指令只做访存；运算指令只做计算。每类指令都有固定格式和执行阶段，易于划分流水线阶段，提高主频与吞吐量。\n\n📘 典型：MIPS 最早提出 5 级流水线 (IF–ID–EX–MEM–WB)，若算术指令能直接访存，这个结构就会完全被打乱。\n\n\n更容易乱序执行和指令重排（Out-of-Order, Superscalar）\n现代 CPU 要并行执行多条指令，需要硬件判断依赖关系。 如果指令可以“随意”访问内存，就必须动态分析：哪些内存地址可能冲突？哪些数据可能重叠？这会极大增加依赖检查逻辑复杂度。\nLoad/Store 模式下，只有特定指令访问内存，依赖关系主要在寄存器之间，硬件能快速判定并行性。\n\n易于编译器优化（Compiler-friendly）\n在 CISC 架构下，编译器很难预测哪些指令会访问内存。\n在 RISC 架构中，编译器能明确控制：什么时候 Load？什么时候 Store？哪些数据在寄存器中？\n编译器可以更高效地调度指令、减少访存次数。\n\n📖 这正是 RISC 设计哲学：“让硬件简单，把复杂性交给编译器。”\n\n\n减少硬件复杂度与译码逻辑\nCISC 指令格式多变、操作数位置复杂， 导致译码单元必须包含：可变长度解码器，多种寻址模式支持，内存操作调度器。\nLoad/Store 架构只需要：固定长度指令（如 RISC-V 的 32 位定长），简单寻址（寄存器 + 立即数），这使得硬件译码速度快，面积小，功耗低。\n\n访存延迟与 Cache 不确定性\n访存操作往往是最慢的部分（几十甚至上百个时钟周期）。如果允许算术指令直接访存，那么算术指令执行时间就会随缓存命中率变化，非常不可预测。\nLoad/Store 机制则能：把访存延迟与算术延迟分离；通过乱序执行、Load-Store 队列、Cache Miss 重叠等手段隐藏访存延迟。\n\n\n\n🔹 “分离存储访问与计算，是现代高性能处理器设计的核心原则。”\n\nA.2 每个晶圆（wafer）上可切割出的芯片（die）数学公式推导\n晶圆直径：$D$\n晶圆半径：$R = \\frac{D}{2}$\n单个芯片（die）面积：$A_d$\n\n如果晶圆是完美的圆，且可以完全填满芯片，那么：\n\nN_{\\text{ideal}} = \\frac{\\pi R^2}{A_d}就是理论最大芯片数。\n但实际中：边缘的芯片不完整，不能用；晶圆是圆的，芯片是方形的；排列方式（行列）造成浪费。\n所以要修正边缘损失（edge loss）。\n经过几何近似（由Texas Instruments早期研究提出），得到常用的经验公式：\n\nN = \\frac{\\pi R^2}{A_d} - \\frac{\\pi D}{\\sqrt{2A_d}}或等价写法：\n\nN = \\frac{\\pi (D/2)^2}{A_d} - \\frac{\\pi D}{\\sqrt{2A_d}}晶圆边缘周长为 $2\\pi R$，假设边缘附近一圈芯片大概率不完整（被切断）。\n每个芯片的有效“边长”约为 $\\sqrt{A_d}$。\n沿圆周一圈能放的芯片数量约为：\n\n\\frac{2\\pi R}{\\sqrt{A_d}}但这些芯片中大约一半面积浪费掉（平均约 50% 被切割），所以要减去一半芯片数：\n\nN_{\\text{edge loss}} \\approx \\frac{1}{2} \\cdot \\frac{2\\pi R}{\\sqrt{A_d}} = \\frac{\\pi R}{\\sqrt{A_d}}将其写成直径形式 $D = 2R$：\n\nN_{\\text{edge loss}} = \\frac{\\pi D}{2\\sqrt{A_d}} = \\frac{\\pi D}{\\sqrt{2A_d}}（不同文献有略微常数差异，此处系数 $\\frac{1}{\\sqrt{2}}$ 是几何拟合结果）\n于是：\n\nN = N_{\\text{ideal}} - N_{\\text{edge loss}}\n= \\frac{\\pi R^2}{A_d} - \\frac{\\pi D}{\\sqrt{2A_d}}","categories":["科学技术 - 计算机体系结构"],"tags":["计算机体系结构","计算机体系结构 - 量化研究方法","学习笔记"]}]